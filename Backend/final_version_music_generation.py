# -*- coding: utf-8 -*-
"""Final_Version_Music_Generation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zNet9slyiTp_EdnaE66rN85MCIR6WugA
"""

# !nvidia-smi

"""# Installation"""

# install the audiocraft liabrary from github
# !python3 -m pip install -U git+https://github.com/facebookresearch/audiocraft#egg=audiocraft

"""# Import necessary libraries"""

# import necessary libraries
from audiocraft.models import musicgen
# from audiocraft.utils.notebook import display_audio
import torch
import julius
from audiocraft.data.audio import audio_write
import torchaudio

"""# Loading the model"""

# | model types are =>      small,  medium,   melody,   large |
# | size of models are =>   300M,   1.5B,     1.5B,     3.3B  |

# model = musicgen.MusicGen.get_pretrained('large', device='cuda')
# model = musicgen.MusicGen.get_pretrained('melody', device='cuda')
model = musicgen.MusicGen.get_pretrained('medium', device='cpu')

"""# Setting the parameters"""

# default values for the generation parameters
default_generation_params = {
    'use_sampling': True,
    'temp': 1.0,
    'top_k': 250,
    'top_p': 0.0,
    'cfg_coef': 3.0,
    'two_step_cfg': False
}

new_generation_params = {}
new_generation_params['use_sampling'] = input("Use sampling (True/False): ").lower() == 'true'
temp_input = input(f"Temperature ({default_generation_params['temp']}): ")
new_generation_params['temp'] = float(temp_input) if temp_input else default_generation_params['temp']
top_k_input = input(f"Top-k ({default_generation_params['top_k']}): ")
new_generation_params['top_k'] = int(top_k_input) if top_k_input else default_generation_params['top_k']
top_p_input = input(f"Top-p ({default_generation_params['top_p']}): ")
new_generation_params['top_p'] = float(top_p_input) if top_p_input else default_generation_params['top_p']
cfg_coef_input = input(f"CFG Coefficient ({default_generation_params['cfg_coef']}): ")
new_generation_params['cfg_coef'] = float(cfg_coef_input) if cfg_coef_input else default_generation_params['cfg_coef']
new_generation_params['two_step_cfg'] = input("Two-step CFG (True/False): ").lower() == 'true'

# Display the selected generation parameters
print("\nSelected Generation Parameters:")
for key, value in new_generation_params.items():
    print(f"{key}: {value}")

# Assign the generated parameters to the model
model.generation_params = new_generation_params

"""# Setting the audio length and providing Prompt input"""

# from IPython.display import Audio

import time

# Define a function for generating and handling user interactions
def generate_audio_with_options():
    # Define default values for audio duration and prompt text
    default_audio_params = {
        'duration': 60,  # Add a default duration value
        'prompt_text': "Enter your prompt (e.g., 'Synthwave And Retro Electro / 80s electronic with drumÂ beats')",
    }

    # Prompt the user to set the audio duration
    duration_input = input(f"Audio duration (seconds, default: {default_audio_params['duration']}): ")
    audio_params = {'duration': int(duration_input) if duration_input else default_audio_params['duration']}

    # Prompt the user for the prompt text with validation
    prompt_text = input(f"{default_audio_params['prompt_text']}: ")
    while not prompt_text:
        print("Prompt text cannot be empty.")
        prompt_text = input(f"{default_audio_params['prompt_text']}: ")

    # Show a "Please wait" message
    print("Generating audio. Please wait...")

    # Generate the audio
    model.set_generation_params(duration=audio_params['duration'])
    res = model.generate([prompt_text], progress=True)

    # Display a message after generating
    print("Audio generation completed.")

    # Automatically save the audio with the provided prompt text in the filename
    file_initials = f"Generated_Audio_{prompt_text}"
    save_location = "./"  # Default location (current directory)

    if write_wav(res, file_initials, save_location):
        print(f"Audio saved as {file_initials}.wav in {save_location}")
        option = input("Do you want to view and play the saved audio? (yes/no): ")

        if option.lower() == "yes":
            # Add space after the user's input
            print("\n")
            audio_path = f"{save_location}/{file_initials}_0.wav"
            # display(Audio(audio_path))
        else:
            print("Audio not viewed or played.")

# Function to write the file to the disk with user-defined location
def write_wav(output, file_initials, save_location):
    try:
        for idx, one_wav in enumerate(output):
            audio_write(f'{save_location}/{file_initials}_{idx}', one_wav.cpu(), model.sample_rate, strategy="loudness", loudness_compressor=True)
            return True
    except Exception as e:
        print("Error while writing the file ", e)
        return None

# Call the function to generate audio with options
generate_audio_with_options()

# """# Audio to Spectrogram"""
#
# import librosa
# import librosa.display
# import matplotlib.pyplot as plt
# import numpy as np
# from google.colab import files
# import os
#
# # Create an "Uploads" folder if it doesn't exist
# uploads_folder = "Uploads"
# if not os.path.exists(uploads_folder):
#     os.makedirs(uploads_folder)
#
# # Ask the user to upload an audio file
# print("Please upload an audio file.")
# uploaded = files.upload()
#
# # Check if a file was uploaded
# if len(uploaded) > 0:
#     # Use the first uploaded file
#     file_name = list(uploaded.keys())[0]
#
#     # Move the uploaded file to the "Uploads" folder
#     new_file_path = os.path.join(uploads_folder, file_name)
#     os.rename(file_name, new_file_path)
#
#     y, sr = librosa.load(new_file_path)
#     D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
#     librosa.display.specshow(D, sr=sr, x_axis="time", y_axis="log")
#     plt.colorbar(format="%+2.0f dB")
#     plt.show()
# else:
#     print("No audio file uploaded.")
#
# """# Identification of Musical Notes and Convertion of the detected notes to MIDI Events
#
#
# """
#
# import locale
# locale.getpreferredencoding = lambda: 'UTF-8'
# !pip install mido
#
# """*Using pydub*"""
#
# from pydub import AudioSegment
# from pydub.playback import play
# import csv
# from mido import MidiFile, MidiTrack, Message
# from google.colab import files
# import os
#
# def pitch_to_midi(pitch):
#     midi_notes = [60 + round(pitch) for pitch in pitch]
#     return midi_notes
#
# def create_midi_file(midi_notes, output_midi):
#     midi_track = MidiTrack()
#
#     for note in midi_notes:
#         # You may want to adjust velocity, time, and other parameters
#         midi_track.append(Message('note_on', note=note, velocity=64, time=0))
#         midi_track.append(Message('note_off', note=note, velocity=64, time=500))  # Adjust duration as needed
#
#     midi_file = MidiFile()
#     midi_file.tracks.append(midi_track)
#     midi_file.save(output_midi)
#
# def identify_and_generate_midi():
#     # Automatically define the output folder path based on the current working directory
#     output_folder_path = os.path.join(os.getcwd(), "output_folder")
#
#     # Create the output folder if it doesn't exist
#     if not os.path.exists(output_folder_path):
#         os.makedirs(output_folder_path)
#
#     # Create a folder for uploaded files
#     uploads_folder = os.path.join(output_folder_path, "Uploads")
#     if not os.path.exists(uploads_folder):
#         os.makedirs(uploads_folder)
#
#     # Loop until a valid audio file is uploaded
#     audio = None
#     while audio is None:
#         # Ask the user to upload an audio file
#         print("Please upload an audio file.")
#         uploaded = files.upload()
#
#         # Check if a file was uploaded
#         if len(uploaded) > 0:
#             # Use the first uploaded file
#             file_name = list(uploaded.keys())[0]
#
#             try:
#                 audio = AudioSegment.from_file(file_name)
#                 # Move the uploaded file to the "Uploads" folder
#                 os.rename(file_name, os.path.join(uploads_folder, file_name))
#             except Exception as e:
#                 print(f"Invalid audio file: {e}")
#         else:
#             print("No audio file uploaded. Please upload a valid audio file.")
#
#     detected_notes = []
#
#     for ms in range(0, len(audio), 100):  # Adjust the frame size as needed
#         frame = audio[ms:ms+100]
#         pitch = frame.dBFS  # This is a simple example; you can use a pitch detection algorithm
#
#         # Ensure that pitch is within a valid range (you may need to adjust this range)
#         if -90 <= pitch <= 0:
#             detected_notes.append(pitch)
#
#     # Map detected pitch values to MIDI notes
#     midi_notes = pitch_to_midi(detected_notes)
#
#     # Create a folder for MIDI files if it doesn't exist
#     midi_folder = os.path.join(output_folder_path, "MIDI")
#     if not os.path.exists(midi_folder):
#         os.makedirs(midi_folder)
#
#     # Create a folder for detected notes CSV files if it doesn't exist
#     csv_folder = os.path.join(output_folder_path, "Detected Notes")
#     if not os.path.exists(csv_folder):
#         os.makedirs(csv_folder)
#
#     # Create output file names
#     audio_file_name = os.path.splitext(os.path.basename(file_name))[0]
#     csv_output_name = os.path.join(csv_folder, f"Detected_Notes_{audio_file_name}_pydub.csv")
#     midi_output_name = os.path.join(midi_folder, f"{audio_file_name}_pydub.mid")
#
#     # Save the detected notes to a CSV file
#     with open(csv_output_name, 'w', newline='') as csvfile:
#         csvwriter = csv.writer(csvfile)
#         csvwriter.writerow(midi_notes)
#
#     # Generate a MIDI file from the detected notes
#     create_midi_file(midi_notes, midi_output_name)
#
#     return csv_output_name, midi_output_name
#
# # Call the function to identify notes and generate a MIDI file
# csv_file, midi_file = identify_and_generate_midi()
#
# # Provide download links for the user
# print(f"Detected Notes CSV file: {csv_file}")
# print(f"MIDI file: {midi_file}")
#
# """*Using aubio*
#
#
# """
#
# import locale
# locale.getpreferredencoding = lambda: 'UTF-8'
# !pip install aubio
#
# import os
# import csv
# import aubio
# from mido import MidiFile, MidiTrack, Message
# from google.colab import files
#
# # Custom function to convert MIDI note numbers to note names
# def midi_to_note(midi_note):
#     note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
#     octave = (midi_note // 12) - 1
#     note = midi_note % 12
#     return f'{note_names[note]}{octave}'
#
# def create_midi_file(midi_notes, output_midi):
#     midi_track = MidiTrack()
#
#     for note in midi_notes:
#         # Adjust other parameters as needed
#         midi_track.append(Message('note_on', note=note, velocity=64, time=0))
#         midi_track.append(Message('note_off', note=note, velocity=64, time=500))  # Adjust duration as needed
#
#     midi_file = MidiFile()
#     midi_file.tracks.append(midi_track)
#     midi_file.save(output_midi)
#
# def identify_and_generate_midi():
#     downsample = 1
#     samplerate = 44100 // downsample
#     win_s = 512 // downsample  # fft size
#     hop_s = 256 // downsample  # hop size
#
#     # Loop until a valid audio file is uploaded
#     audio = None
#     uploaded_file_path = None  # Store the uploaded file path
#     while audio is None:
#         # Ask the user to upload an audio file
#         print("Please upload an audio file.")
#         uploaded = files.upload()
#
#         # Check if a file was uploaded
#         if len(uploaded) > 0:
#             # Use the first uploaded file
#             file_name = list(uploaded.keys())[0]
#             uploaded_file_path = file_name
#
#             try:
#                 audio = aubio.source(uploaded_file_path, samplerate, hop_s)
#             except Exception as e:
#                 print(f"Invalid audio file: {e}")
#         else:
#             print("No audio file uploaded. Please upload a valid audio file.")
#
#     tolerance = 0.8
#
#     notes_o = aubio.notes("default", win_s, hop_s, samplerate)
#
#     detected_notes = []
#
#     # Total number of frames read
#     total_frames = 0
#     while True:
#         samples, read = audio()
#         new_note = notes_o(samples)
#         if (new_note[0] != 0):
#             note_str = midi_to_note(int(new_note[0]))  # Convert the MIDI note to a string note
#             detected_notes.append(int(new_note[0]))  # Convert the MIDI note to an integer
#         total_frames += read
#         if read < hop_s:
#             break
#
#     # Automatically create the folders if they don't exist
#     output_folder_path = os.path.join(os.getcwd(), "output_folder")
#     folders_to_create = ["MIDI", "Detected Notes"]
#     for folder_name in folders_to_create:
#         folder_path = os.path.join(output_folder_path, folder_name)
#         if not os.path.exists(folder_path):
#             os.makedirs(folder_path)
#
#     # Extract audio file name
#     audio_file_name = os.path.splitext(os.path.basename(uploaded_file_path))[0]
#     csv_output_name = os.path.join(output_folder_path, "Detected Notes", f"Detected_Notes_{audio_file_name}_aubio.csv")
#     midi_output_name = os.path.join(output_folder_path, "MIDI", f"{audio_file_name}_aubio.mid")
#
#     # Save the detected notes to a CSV file
#     with open(csv_output_name, 'w', newline='') as csvfile:
#         csvwriter = csv.writer(csvfile)
#         csvwriter.writerow(detected_notes)
#
#     # Generate a MIDI file from the detected notes
#     create_midi_file(detected_notes, midi_output_name)
#
#     return csv_output_name, midi_output_name
#
# # Call the function to identify notes and generate a MIDI file
# csv_file, midi_file = identify_and_generate_midi()
#
# # Provide download links for the user
# print(f"Detected Notes CSV file: {csv_file}")
# print(f"MIDI file: {midi_file}")